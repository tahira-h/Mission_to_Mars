{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "diagnostic-ethernet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: splinter in c:\\users\\tahira\\anaconda3\\lib\\site-packages (0.14.0)\n",
      "Requirement already satisfied: selenium>=3.141.0 in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from splinter) (3.141.0)\n",
      "Requirement already satisfied: six in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from splinter) (1.15.0)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from selenium>=3.141.0->splinter) (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install splinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bottom-bobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: webdriver_manager in c:\\users\\tahira\\anaconda3\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: crayons in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from webdriver_manager) (0.4.0)\n",
      "Requirement already satisfied: requests in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from webdriver_manager) (2.25.1)\n",
      "Requirement already satisfied: configparser in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from webdriver_manager) (5.0.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from crayons->webdriver_manager) (0.4.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from requests->webdriver_manager) (2020.12.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "derived-homework",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bs4 in c:\\users\\tahira\\anaconda3\\lib\\site-packages (0.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from bs4) (4.9.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\tahira\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "handled-bosnia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in c:\\users\\tahira\\anaconda3\\lib\\site-packages (3.11.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "corresponding-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import tools Splinter and BeautifulSoup\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "refined-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "relative-share",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n",
      "[WDM] - Current google-chrome version is 89.0.4389\n",
      "[WDM] - Get LATEST driver version for 89.0.4389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\TAHIRA\\.wdm\\drivers\\chromedriver\\win32\\89.0.4389.23\\chromedriver.exe] found in cache\n"
     ]
    }
   ],
   "source": [
    "# Set up Splinter\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "verified-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Mars Data: The News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "welsh-prayer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visit the mars nasa new site\n",
    "url = 'https://redplanetscience.com'\n",
    "browser.visit(url)\n",
    "\n",
    "# Optional delay for loading the page\n",
    "browser.is_element_present_by_css('div.list_text', wait_time=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dangerous-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the HTML parser\n",
    "html = browser.html\n",
    "news_soup = soup(html, 'html.parser')\n",
    "slide_elem = news_soup.select_one('div.list_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alike-radius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"content_title\">NASA Mars Mission Connects With Bosnian and Herzegovinian Town</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin scraping\n",
    "slide_elem.find('div', class_='content_title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "specialized-norfolk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NASA Mars Mission Connects With Bosnian and Herzegovinian Town'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's get just the text, not the HTML tags or elements\n",
    "\n",
    "# Use the parent element to find the first 'a' tag and save it as 'news_title'\n",
    "news_title = slide_elem.find('div', class_='content_title').get_text()\n",
    "news_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "structured-violation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note:\n",
    "# If using '.find_all()' instead of '.find()' when pulling the summary, we would retrieve all of the summaries on the page instead of just the first one. '.find()' is to retrieve the first tags and attributes, or first summary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "subjective-spectacular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A letter from NASA was presented to the mayor of Jezero, Bosnia-Herzegovina, honoring the connection between the town and Jezero Crater, the Mars 2020 rover landing site.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the parent element to find the paragraph text\n",
    "news_p = slide_elem.find('div', class_='article_teaser_body').get_text()\n",
    "news_p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alert-miracle",
   "metadata": {},
   "source": [
    "### Featured Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "armed-supervision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Mars Data: Featured Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cultural-omaha",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visit URL \n",
    "url = 'https://spaceimages-mars.com/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "following-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and click the full image button\n",
    "full_image_elem = browser.find_by_tag('button')[1]\n",
    "full_image_elem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "logical-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse to continue and scrape the full-size image URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "illegal-correlation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the resulting html with soup\n",
    "html = browser.html\n",
    "img_soup = soup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "changed-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the image tag and class (<img /> and fancybox-img) to build the URL to the full-size image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "international-missile",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image/featured/mars2.jpg'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the relative image url\n",
    "img_url_rel = img_soup.find('img', class_='fancybox-image').get('src')\n",
    "img_url_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "different-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When looking at our address bar in the webpage, can see the entire URL up there already; we need to add the first portion to the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "noticed-banana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://spaceimages-mars.com/image/featured/mars2.jpg'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the base URL to create an absolute URL\n",
    "img_url = f'https://spaceimages-mars.com/{img_url_rel}'\n",
    "img_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "vital-curtis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: \n",
    "# f-string print statements as shown above is a cleaner way to create print statements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "stock-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Mars Data: Mars Facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "corresponding-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder: \n",
    "# import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rational-field",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<table border=\"1\" class=\"dataframe\">\\n  <thead>\\n    <tr style=\"text-align: right;\">\\n      <th></th>\\n      <th>Mars</th>\\n      <th>Earth</th>\\n    </tr>\\n    <tr>\\n      <th>description</th>\\n      <th></th>\\n      <th></th>\\n    </tr>\\n  </thead>\\n  <tbody>\\n    <tr>\\n      <th>Mars - Earth Comparison</th>\\n      <td>Mars</td>\\n      <td>Earth</td>\\n    </tr>\\n    <tr>\\n      <th>Diameter:</th>\\n      <td>6,779 km</td>\\n      <td>12,742 km</td>\\n    </tr>\\n    <tr>\\n      <th>Mass:</th>\\n      <td>6.39 × 10^23 kg</td>\\n      <td>5.97 × 10^24 kg</td>\\n    </tr>\\n    <tr>\\n      <th>Moons:</th>\\n      <td>2</td>\\n      <td>1</td>\\n    </tr>\\n    <tr>\\n      <th>Distance from Sun:</th>\\n      <td>227,943,824 km</td>\\n      <td>149,598,262 km</td>\\n    </tr>\\n    <tr>\\n      <th>Length of Year:</th>\\n      <td>687 Earth days</td>\\n      <td>365.24 days</td>\\n    </tr>\\n    <tr>\\n      <th>Temperature:</th>\\n      <td>-87 to -5 °C</td>\\n      <td>-88 to 58°C</td>\\n    </tr>\\n  </tbody>\\n</table>'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape the entire table with .read_html() function\n",
    "df = pd.read_html('https://galaxyfacts-mars.com')[0]\n",
    "df.columns=['description', 'Mars', 'Earth']\n",
    "df.set_index('description', inplace=True)\n",
    "# Convert the DataFrame back into HTML-ready code using .to_html() function\n",
    "df.to_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "characteristic-steal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# Now that everything is gathered, end the automated browsing session by using browser.quit()\n",
    "\n",
    "# Without browser.quit(), the browser will not know when to shut down. It iwll continue to listen for instructions and use the computer's resources, putting a strain on memory or laptop/computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "decimal-happiness",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
